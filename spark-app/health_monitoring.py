from pyspark.sql import SparkSession
from pyspark.sql.types import *
from datetime import datetime
import json
from pyspark import SparkFiles

# This token JSON file is autogenerated when you download your token, 
# if yours is different, update the file name below
with open("/opt/spark-app/yahiamahmoood333@gmail.com-token.json") as f:
  secrets = json.load(f)

CLIENT_ID = secrets["clientId"]
CLIENT_SECRET = secrets["secret"]

# Distribute the secure connect bundle to all executors
spark = SparkSession.builder \
  .appName("Healthcare Monitoring") \
  .config("spark.cassandra.auth.username", CLIENT_ID) \
  .config("spark.cassandra.auth.password", CLIENT_SECRET) \
  .getOrCreate()

# Add the secure connect bundle file to Spark's context to be distributed to all executors
spark.sparkContext.addFile("/opt/spark-app/secure-connect-healthcare-streaming.zip")

# Get the path to the file from SparkFiles (ensures it works on all executors)
# bundle_path = SparkFiles.get("secure-connect-healthcare-streaming.zip")

# Create Spark session with Cassandra connection options using the secure connect bundle
spark = SparkSession.builder \
  .appName("Healthcare Monitoring") \
  .config("spark.cassandra.connection.config.cloud.path", "secure-connect-healthcare-streaming.zip") \
  .config("spark.cassandra.auth.username", CLIENT_ID) \
  .config("spark.cassandra.auth.password", CLIENT_SECRET) \
  .getOrCreate()

# SparkContext from sparkSession to reduce written code only
sc = spark.sparkContext

# Schema (This Schema is also the same in Cassandra on DataStax)
schema = StructType([
  StructField("id", StringType(), False),
  StructField("time", TimestampType(), False),
  StructField("age", StringType(), True),
  StructField("bmi", DoubleType(), True),
  StructField("bpm", DoubleType(), True),
  StructField("calories", DoubleType(), True),
  StructField("distance", DoubleType(), True),
  StructField("gender", StringType(), True),
  StructField("steps", IntegerType(), True),
])

# Just for testing -----------------------------------------------------
# (If this record is added before cassandra will not generate new one)
example = spark.createDataFrame([
  (
    "621e2e8e67b776a24055b564",
    datetime.strptime("2021-05-24 10:00:00", "%Y-%m-%d %H:%M:%S"),
    "<19",
    20.0,
    85.5,
    85.5,
    100.0,
    "MALE",
    25
  )
], schema)

print(example.show())

# Write the example dataframe to Cassandra
example.write \
  .format("org.apache.spark.sql.cassandra") \
  .option("keyspace", "healthcare") \
  .option("table", "stream") \
  .mode("append") \
  .save()
